# -*- coding: utf-8 -*-
"""Diabetes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BSFyk9MQtlL3-MxVslPIPdlenf62Z6qg
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset dari Pima Indias Diabetes
df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/pima-diabetes.csv')

# Menampilkan informasi awal dataset
print("Informasi Dataset:")
print(df.info())
print("\nStatistik Deskriptif:")
print(df.describe())

# Visualisasi distribusi awal setiap fitur
plt.figure(figsize=(15, 10))
df.hist(bins=20, figsize=(15, 10), grid=False)
plt.tight_layout()
plt.show()

"""Pra-Pemrosesan 2 | Pengecekan Missing Values"""

import numpy as np
from sklearn.impute import SimpleImputer

# Membaca file CSV berdasarkan data df yang sudah dipanggil diatas dan dimasukan ke variable baru
cardata = df

# Menampilkan DataFrame
print("DataFrame:")
print(cardata)

# Menampilkan Jumlah Missing Values per Kolom
print("Jumlah Missing Values per Kolom:")
print(cardata.isnull().sum())

# Identifikasi nilai nol pada kolom tertentu
cols_with_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
print("\nJumlah nilai nol sebelum imputasi:")
print(df[cols_with_zero].isnull().sum())

# Ganti nol dengan NaN
for col in cols_with_zero:
    df[col].replace(0, np.nan, inplace=True)

# Visualisasi nilai nol (sebelum imputasi)
plt.figure(figsize=(10, 6))
sns.heatmap(df.isnull(), cbar=False, cmap="viridis")
plt.title("Nilai Nol Sebelum Imputasi")
plt.show()

# Imputasi nilai NaN dengan rata-rata
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy="mean")
df[cols_with_zero] = imputer.fit_transform(df[cols_with_zero])

print("\nJumlah nilai nol setelah imputasi:")
print(df[cols_with_zero].isnull().sum())

# Visualisasi outlier sebelum penanganan
plt.figure(figsize=(15, 8))
df[cols_with_zero].boxplot()
plt.title("Boxplot Sebelum Penanganan Outlier")
plt.show()

# Deteksi dan menangani outlier menggunakan IQR
for col in cols_with_zero:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])
    df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])

# Visualisasi setelah penanganan outlier
plt.figure(figsize=(15, 8))
df[cols_with_zero].boxplot()
plt.title("Boxplot Setelah Penanganan Outlier")
plt.show()

from sklearn.preprocessing import StandardScaler

# Normalisasi data
scaler = StandardScaler()
df_scaled = pd.DataFrame(scaler.fit_transform(df.drop('Outcome', axis=1)), columns=df.columns[:-1])

# Visualisasi distribusi setelah normalisasi
plt.figure(figsize=(15, 10))
df_scaled.hist(bins=20, figsize=(15, 10), grid=False)
plt.suptitle("Distribusi Setelah Normalisasi")
plt.tight_layout()
plt.show()

from collections import Counter
from imblearn.over_sampling import SMOTE

# Visualisasi distribusi kelas sebelum oversampling
plt.figure(figsize=(6, 4))
sns.countplot(x=df['Outcome'])
plt.title("Distribusi Kelas Sebelum Oversampling")
plt.show()

# Oversampling dengan SMOTE
X = df.drop('Outcome', axis=1)
y = df['Outcome']

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Visualisasi distribusi kelas setelah oversampling
plt.figure(figsize=(6, 4))
sns.countplot(x=y_resampled)
plt.title("Distribusi Kelas Setelah Oversampling")
plt.show()

from sklearn.model_selection import train_test_split

# Membagi dataset menjadi data latih dan data uji
X_train, X_test, y_train, y_test = train_test_split(
    X_resampled, y_resampled, test_size=0.2, random_state=42
)

print(f"Data latih: {X_train.shape}, Data uji: {X_test.shape}")

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Pembuatan model Random Forest
rf_model = RandomForestClassifier(
    n_estimators=100,  # Jumlah pohon
    max_depth=None,    # Kedalaman pohon tidak dibatasi
    random_state=42,   # Reproducibility
    class_weight="balanced"  # Menangani ketidakseimbangan kelas
)

# Melatih model pada data latih
rf_model.fit(X_train, y_train)

# Prediksi pada data uji
rf_preds = rf_model.predict(X_test)

# Probabilitas untuk ROC curve
rf_probs = rf_model.predict_proba(X_test)[:, 1]

# Evaluasi model
print("=== Classification Report ===")
print(classification_report(y_test, rf_preds))

# Confusion Matrix
plt.figure(figsize=(6, 5))
sns.heatmap(confusion_matrix(y_test, rf_preds), annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Confusion Matrix: Random Forest")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ROC Curve
rf_auc = roc_auc_score(y_test, rf_probs)
rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)

plt.figure(figsize=(8, 6))
plt.plot(rf_fpr, rf_tpr, label=f"Random Forest (AUC = {rf_auc:.2f})")
plt.plot([0, 1], [0, 1], "k--", label="No Skill")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve: Random Forest")
plt.legend()
plt.grid()
plt.show()

from sklearn.ensemble import RandomForestClassifier

# Inisiasi Model Random Forest
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Training model dengan .fit()
model.fit(X_train, y_train)

# Evaluasi model
y_pred = model.predict(X_test)
accuracy = model.score(X_test, y_test)

print(f"Accuracy Model Random Forest: {accuracy:.2f}")

# Prediksi pada data test

y_pred = model.predict(X_test)
y_pred

y_test

# Memeriksa antara hasil prediksi dan data aktual

df = pd.DataFrame({'Prediksi': y_pred, 'Aktual': y_test})
df

# prompt: save model

import pickle

# Save the model to a file
with open('diabetes.sav', 'wb') as file:
    pickle.dump(model, file)